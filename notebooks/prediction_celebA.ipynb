{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prediction_celebA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF_epVBGrpmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = ['5_o_Clock_Shadow','Arched_Eyebrows','Attractive','Bags_Under_Eyes','Bald','Bangs','Big_Lips','Big_Nose','Black_Hair',\n",
        " 'Blond_Hair', 'Blurry','Brown_Hair','Bushy_Eyebrows','Chubby','Double_Chin','Eyeglasses','Goatee','Gray_Hair','Heavy_Makeup',\n",
        " 'High_Cheekbones','Male','Mouth_Slightly_Open','Mustache','Narrow_Eyes','No_Beard','Oval_Face','Pale_Skin','Pointy_Nose',\n",
        " 'Receding_Hairline','Rosy_Cheeks','Sideburns','Smiling','Straight_Hair','Wavy_Hair','Wearing_Earrings','Wearing_Hat',\n",
        " 'Wearing_Lipstick','Wearing_Necklace','Wearing_Necktie','Young']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38aKAmXjtrvm",
        "colab_type": "code",
        "outputId": "d33a98da-dc3e-49a7-859c-98f15461b492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE9wAJFztsfs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "8f735b7a-c50f-4bbb-a68c-bf1d3755fc28"
      },
      "source": [
        "!ls drive/My\\ Drive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Assignment 1.ipynb'\t\t   PyTorch_multi_label_classifier.ipynb\n",
            " cartisan_assessment_exercise_2    Pytorch_textdata.ipynb\n",
            " CelebA\t\t\t\t  'simple_dogcat_classifier (1).ipynb'\n",
            "'Colab Notebooks'\t\t   simple_dogcat_classifier.ipynb\n",
            " del-data.csv.tar.gz\t\t   train-recognizer.ipynb\n",
            " dogcat_classifier.ipynb\t   Untitled0.ipynb\n",
            " dogcat_classifier_vgg.ipynb\t   Untitled1.ipynb\n",
            " download_files.ipynb\t\t   Untitled2.ipynb\n",
            " drive_setup.ipynb\t\t   Untitled3.ipynb\n",
            "'Getting started.pdf'\t\t   Untitled4.ipynb\n",
            " iisc_blr_task\t\t\t   Untitled5.ipynb\n",
            " Image_1.zip\t\t\t  'Untitled document.gdoc'\n",
            " kaggle.json\t\t\t   variance_all_humidity.ipynb\n",
            " Model_40_EPCHS\t\t\t   variance_all.ipynb\n",
            " python_celeba_multi-label.ipynb   variance_all_light.ipynb\n",
            " pytorch1.ipynb\t\t\t   variance_all_voltage.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOnV_NgjuGVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHgIi1dEuZQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiClassifier, self).__init__()\n",
        "        self.ConvLayer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3), # 3, 256, 256\n",
        "            nn.MaxPool2d(2), # op: 16, 127, 127\n",
        "            nn.ReLU(), # op: 64, 127, 127\n",
        "        )\n",
        "        self.ConvLayer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3), # 64, 127, 127   \n",
        "            nn.MaxPool2d(2), #op: 128, 63, 63\n",
        "            nn.ReLU() # op: 128, 63, 63\n",
        "        )\n",
        "        self.ConvLayer3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 3), # 128, 63, 63\n",
        "            nn.MaxPool2d(2), #op: 256, 30, 30\n",
        "            nn.ReLU() #op: 256, 30, 30\n",
        "        )\n",
        "        self.ConvLayer4 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, 3), # 256, 30, 30\n",
        "            nn.MaxPool2d(2), #op: 512, 14, 14\n",
        "            nn.ReLU(), #op: 512, 14, 14\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "        self.Linear1 = nn.Linear(512 * 14 * 14, 1024)\n",
        "        self.Linear2 = nn.Linear(1024, 256)\n",
        "        self.Linear3 = nn.Linear(256, 40)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.ConvLayer1(x)\n",
        "        x = self.ConvLayer2(x)\n",
        "        x = self.ConvLayer3(x)\n",
        "        x = self.ConvLayer4(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.Linear1(x)\n",
        "        x = self.Linear2(x)\n",
        "        x = self.Linear3(x)\n",
        "        return F.sigmoid(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKnkPlVVuqAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = 'drive/My Drive/Model_40_EPCHS'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxueN8DUu32Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load(model_path, map_location=torch.device('cpu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKHjJfZUu5y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tensor(img):\n",
        "    tfms = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    \n",
        "    return tfms(Image.open(img)).unsqueeze(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AigX-RaUvYd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(img, label_lst, model):\n",
        "    tnsr = get_tensor(img)\n",
        "    op = model(tnsr)\n",
        "    op_b = torch.round(op)\n",
        "    \n",
        "    op_b_np = torch.Tensor.cpu(op_b).detach().numpy()\n",
        "    \n",
        "    preds = np.where(op_b_np == 1)[1]\n",
        "    \n",
        "    print(preds)\n",
        "    \n",
        "    label = []\n",
        "    for i in preds:\n",
        "        label.append(label_lst[i])\n",
        "        \n",
        "    return label, op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbKiBG6W0fGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "18c639a4-dfdd-441c-c971-35649656c92b"
      },
      "source": [
        "predict('/content/images.jpeg', labels, model)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  7 20 24 32 34]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['5_o_Clock_Shadow',\n",
              "  'Big_Nose',\n",
              "  'Male',\n",
              "  'No_Beard',\n",
              "  'Straight_Hair',\n",
              "  'Wearing_Earrings'],\n",
              " tensor([[6.2407e-01, 4.2582e-09, 2.2081e-03, 8.6636e-03, 1.7147e-07, 4.9673e-04,\n",
              "          5.3532e-05, 5.7182e-01, 1.9525e-02, 1.8435e-06, 1.3335e-01, 5.6491e-07,\n",
              "          4.0920e-03, 1.6351e-05, 7.5260e-04, 4.1949e-01, 9.5306e-03, 6.3661e-04,\n",
              "          3.3259e-07, 1.5029e-04, 9.9932e-01, 7.8361e-02, 2.3443e-01, 4.0281e-05,\n",
              "          8.8718e-01, 6.4305e-04, 1.7309e-06, 4.7559e-03, 2.4093e-03, 2.0086e-03,\n",
              "          4.0016e-02, 8.7549e-07, 6.6590e-01, 1.0298e-05, 6.7072e-01, 2.9100e-04,\n",
              "          2.2234e-06, 2.8025e-04, 4.1978e-07, 1.2359e-03]],\n",
              "        grad_fn=<SigmoidBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    }
  ]
}